{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import hashlib\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "shingling_size = 10\n",
    "signature_size = 50\n",
    "bands_nr = 10\n",
    "threshold = 0.7\n",
    "upper_threshold = 0.95\n",
    "user_thereshold = 3\n",
    "\n",
    "total_tweets = 0.005"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos y sacar muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'screen_name', 'text'], dtype='object')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req_cols = ['id','screen_name','text']\n",
    "row_num = math.ceil(total_tweets * 4594980)  # 20% de los datos\n",
    "\n",
    "# Abrir el archivo CSV y procesarlo línea por línea\n",
    "tweets_df = pd.read_csv(\"tweets_2022_abril_junio.csv\", usecols=req_cols, nrows=row_num)\n",
    "\n",
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22975"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_nr = len(tweets_df)\n",
    "doc_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22975it [00:01, 11536.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(tweets_df.iterrows()):\n",
    "    text = row['text'].replace('\\n', '').replace('\\r', '')\n",
    "    text = re.sub(r'^RT\\s+@\\w+:\\s+', '',text).lower()\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = text.lstrip(' ').rstrip(' ')\n",
    "    tweets_df.at[index, 'text'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1512186166438637582</td>\n",
       "      <td>h0l4d4ni3l4</td>\n",
       "      <td>tras casi 50 años del golpe, la constitución s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1512186202367045642</td>\n",
       "      <td>Claudio70932894</td>\n",
       "      <td>mañana jueves a las 18hrs. comienza nuestro pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1512186287284924418</td>\n",
       "      <td>Cesar_A_RR</td>\n",
       "      <td>aquí está el aporte de  con respecto a los der...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1512186335754301446</td>\n",
       "      <td>rosmarieher</td>\n",
       "      <td>la pelotudez no tiene limites...no tiene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1512186407841767424</td>\n",
       "      <td>GQuelluen</td>\n",
       "      <td>ante la circulación de noticias falsas, les qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      screen_name   \n",
       "0  1512186166438637582      h0l4d4ni3l4  \\\n",
       "1  1512186202367045642  Claudio70932894   \n",
       "2  1512186287284924418       Cesar_A_RR   \n",
       "3  1512186335754301446      rosmarieher   \n",
       "4  1512186407841767424        GQuelluen   \n",
       "\n",
       "                                                text  \n",
       "0  tras casi 50 años del golpe, la constitución s...  \n",
       "1  mañana jueves a las 18hrs. comienza nuestro pr...  \n",
       "2  aquí está el aporte de  con respecto a los der...  \n",
       "3           la pelotudez no tiene limites...no tiene  \n",
       "4  ante la circulación de noticias falsas, les qu...  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener Shingles por tweet y todos los shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22975/22975 [00:00<00:00, 44216.98it/s]\n"
     ]
    }
   ],
   "source": [
    "k = 5 ## Largo de los shingles\n",
    "tweets_df[\"shingles\"] = [set([tweet[i:i+k] for i in range(len(tweet) - k + 1)]) for tweet in tqdm(tweets_df[\"text\"])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similitud de Jaccard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de Hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hashFamily:\n",
    "    def __init__(self, i):\n",
    "        self.resultSize = 8 # how many bytes we want back\n",
    "        self.maxLen = 20 # how long can our i be (in decimal)\n",
    "        self.salt = str(i).zfill(self.maxLen)[-self.maxLen:]\n",
    "        \n",
    "    def get_hash_value(self, el_to_hash):\n",
    "        return int(hashlib.sha1(str(el_to_hash).encode('utf-8') + self.salt.encode('utf-8')).hexdigest()[-self.resultSize:], 16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculamos el minhash de los tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class minhashSigner:\n",
    "    def __init__(self, sig_size):\n",
    "        self.sig_size=sig_size\n",
    "        self.hash_functions = [hashFamily(randint(0,10000000000)) for i in range(0,sig_size)]\n",
    "    \n",
    "    def compute_set_signature(self, set_):\n",
    "        set_sig = []\n",
    "        for h_funct in self.hash_functions:\n",
    "            min_hash = math.inf\n",
    "            for el in set_:\n",
    "                h = h_funct.get_hash_value(el)\n",
    "                if h < min_hash:\n",
    "                    min_hash = h\n",
    "                \n",
    "            set_sig.append(min_hash)\n",
    "        \n",
    "        return set_sig\n",
    "    \n",
    "    #return a list of lists that can be seen as the signature matrix\n",
    "    def compute_signature_matrix(self, set_list):\n",
    "        signatures = []\n",
    "        for s in tqdm(set_list):\n",
    "            signatures.append( self.compute_set_signature(s) )\n",
    "            \n",
    "        return signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22975/22975 [02:18<00:00, 166.21it/s]\n"
     ]
    }
   ],
   "source": [
    "signature_size = 50\n",
    "shingling_list = tweets_df[\"shingles\"]\n",
    "signer = minhashSigner(signature_size)\n",
    "signature_matrix = signer.compute_signature_matrix( shingling_list )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Almacenamos los minhash para ahorrar tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('minhash.txt', signature_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH (Locality Sensitive Hashing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lsh:\n",
    "    def __init__(self, threshold=0.8):\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def get_signature_matrix_bands(self, sig_matrix, bands_nr, sign_len): \n",
    "        #bands_nr = b\n",
    "        #sign_len = n\n",
    "        r = int(sign_len/bands_nr) #number of rows in each band\n",
    "        bands = {} # {band_nr: [col_1,col_2,...]} where col_1 is all the values of Sig(S_i) for band b.\n",
    "        for i in range(0,bands_nr):\n",
    "            bands[i] = []\n",
    "        \n",
    "        # put Subsets of the columns of signature matrix into the appropriate bucket and cosider a column \n",
    "        # as a unique block so that we can hash the entire column.\n",
    "        # Basically a band is a list of element, where each element is a subset of a signature of a given set.\n",
    "        for signature in sig_matrix: \n",
    "            \n",
    "            for i in range(0, bands_nr):\n",
    "                idx = i*r    \n",
    "                bands[i].append(' '.join(str(x) for x in signature[idx:idx+r]) ) \n",
    "                    \n",
    "        return bands\n",
    "\n",
    "    #band is a list \n",
    "    # construct a dictionary {hash(band_column): doc_id that produced this hash}\n",
    "    def get_band_buckets(self, band, hash_funct):\n",
    "        buckets = {}\n",
    "        for doc_id in range(0,len(band)):\n",
    "            value = hash_funct.get_hash_value( band[doc_id] )\n",
    "            if value not in buckets:\n",
    "                buckets[value] = [doc_id]\n",
    "            else:\n",
    "                 buckets[value].append(doc_id)\n",
    "                \n",
    "        return buckets\n",
    "    \n",
    "    def get_candidates_list(self, buckets):\n",
    "        candidates = set()\n",
    "        # buckets is a dictionary containing key=bucket, value= list of doc_ids that hashed to bucket\n",
    "        for bucket,candidate_list in buckets.items():\n",
    "            if len(candidate_list) > 1:\n",
    "                for i in range(0,len(candidate_list)-1):\n",
    "                    for j in range(i+1,len(candidate_list)):  \n",
    "                        pair = tuple(sorted( (candidate_list[i],candidate_list[j]) ))\n",
    "                        candidates.add(pair)\n",
    "                \n",
    "        return candidates #ie a set of couples, each couple is a candidate pair\n",
    "    \n",
    "    def check_candidates(self, candidates_list, threshold, sigs):\n",
    "        similar_docs = set() #set of tuples\n",
    "        # similar_pair is a couple containing doc_ids of documents that hashed to same bucket\n",
    "        for  similar_pair in candidates_list:\n",
    "            #for all the pairs of document in the list check similarity of their signatures\n",
    "            doc_id_1 = similar_pair[0]\n",
    "            doc_id_2 = similar_pair[1]\n",
    "            signature_1 = set(sigs[doc_id_1]) #get the i-th column from signature matrix where i is doc_id in the collision list\n",
    "            signature_2 = set(sigs[doc_id_2])\n",
    "            js = len(signature_1.intersection(signature_2)) /len(signature_1.union(signature_2))\n",
    "            \n",
    "            if js >= threshold and js < upper_threshold:\n",
    "                similar_docs.add( tuple(sorted((doc_id_1,doc_id_2) )) )\n",
    "                        \n",
    "                        \n",
    "        return similar_docs\n",
    "    \n",
    "    def get_similar_items(self, sig_matrix, bands_nr, sign_len):\n",
    "        similar_docs = set()\n",
    "        #divide signature matrix into bands\n",
    "        bands = self.get_signature_matrix_bands(sig_matrix,bands_nr,sign_len)\n",
    "        \n",
    "        #for all the bands\n",
    "        for band_id, elements in tqdm(bands.items()):\n",
    "            #produce the buckets for the given band (band_id) with a random hash function\n",
    "            buckets = self.get_band_buckets(elements, hash_funct=hashFamily(randint(0,10000000000)))\n",
    "            #Get all the candidate pairs\n",
    "            candidates = self.get_candidates_list(buckets)\n",
    "            #Check all candidate pairs' signatures\n",
    "            for sim_tuple in self.check_candidates(candidates, self.threshold, sig_matrix):\n",
    "                similar_docs.add( sim_tuple)\n",
    "\n",
    "        return similar_docs #return all the similar signatures that respect the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:16<00:00,  7.61s/it]\n"
     ]
    }
   ],
   "source": [
    "lsh_instance = lsh(threshold)\n",
    "lsh_similar_itemset = lsh_instance.get_similar_items(signature_matrix, bands_nr, signature_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 914/914 [00:00<00:00, 3487.13it/s]\n"
     ]
    }
   ],
   "source": [
    "user_candidates = dict()\n",
    "tweets_candidates = dict()\n",
    "\n",
    "for i in tqdm(range(len(lsh_similar_itemset))):    \n",
    "    docs = lsh_similar_itemset.pop()\n",
    "    tweet1_name = tweets_df.iloc[docs[0]][\"screen_name\"]\n",
    "    tweet2_name = tweets_df.iloc[docs[1]][\"screen_name\"]\n",
    "    tweet1_text = tweets_df.iloc[docs[0]][\"text\"]\n",
    "    tweet2_text = tweets_df.iloc[docs[1]][\"text\"]\n",
    "    names = tuple(sorted((tweet1_name,tweet2_name)))\n",
    "    if tweet1_name != tweet2_name:\n",
    "        if names not in user_candidates.keys():\n",
    "            user_candidates[names] = 1\n",
    "            tweets_candidates[names] = [[tweet1_text],[tweet2_text]]\n",
    "        else:\n",
    "            user_candidates[names] += 1\n",
    "            tweets_candidates[names][0].append(tweet1_text)\n",
    "            tweets_candidates[names][1].append(tweet2_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824\n"
     ]
    }
   ],
   "source": [
    "print(len(user_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando usuarios ('Masryaalbi', 'libertarioconte'), con 23 tweets similares\n",
      "Tweet 1 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 1 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 2 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 2 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 3 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 3 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 4 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 4 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 5 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 5 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 6 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 6 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 7 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 7 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 8 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 8 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 9 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 9 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 10 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 10 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 11 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 11 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 12 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 12 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 13 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 13 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 14 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 14 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 15 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 15 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 16 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 16 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 17 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 17 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 18 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 18 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 19 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 19 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 20 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 20 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 21 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 21 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 22 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 22 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "Tweet 23 del Usuario: Masryaalbi\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvl…\n",
      "Tweet 23 del Usuario: libertarioconte\n",
      "destruye en segundos al chanta de baradit!!! rt  https://t.co/gcxixvlohy\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in user_candidates:\n",
    "    if user_candidates[i] >= user_thereshold:\n",
    "        print(f\"Evaluando usuarios {i}, con {user_candidates[i]} tweets similares\")\n",
    "        for j in range(user_candidates[i]):\n",
    "            print(f\"Tweet {j + 1} del Usuario: {i[0]}\")\n",
    "            print(tweets_candidates[i][0][j])\n",
    "            print(f\"Tweet {j + 1} del Usuario: {i[1]}\")\n",
    "            print(tweets_candidates[i][1][j])\n",
    "        print(\"-----------------------------------------\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
